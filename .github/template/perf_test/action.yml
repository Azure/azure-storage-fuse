name: perf_test
description: "Execute the performance test"

inputs:
  TYPE: 
    required: true
    description: "Type of storage account"  
  TOKEN:   
    required: true
    description: "Token for checkin"  

runs:
  using: "composite"
  
  steps:
    # ---------------------------------------------------------------------------------------------------------------------------------------------------
    # Run the basic tests using FIO

    # Run the Read tests
    - name: "Read Test"
      uses: "./.github/template/generate_page"
      with:
        TEST: "read"
        TYPE: ${{ inputs.TYPE }}
        TOKEN: ${{ inputs.TOKEN }}

    # Run the Write tests with high number of threads
    - name: "High threads Test"
      uses: "./.github/template/generate_page"
      with:
        TEST: "highlyparallel"
        TYPE: ${{ inputs.TYPE }}
        TOKEN: ${{ inputs.TOKEN }}
  
    # Run the Write tests
    - name: "Write Test"
      uses: "./.github/template/generate_page"
      with:
        TEST: "write"
        TYPE: ${{ inputs.TYPE }}
        TOKEN: ${{ inputs.TOKEN }}
          
    # Run the Create tests
    - name: "Create File Test"
      uses: "./.github/template/generate_page"
      with:
        TEST: "create"
        TYPE: ${{ inputs.TYPE }}
        TOKEN: ${{ inputs.TOKEN }}
    # ---------------------------------------------------------------------------------------


    # Below tests needs to run seperatly as output is different
    # ---------------------------------------------------------------------------------------------------
    # Run the List tests
    # this shall always runs after create tests
    - name: "List File Test"
      shell: bash
      run: |
        rm -rf /mnt/blob_mnt/*
        rm -rf /mnt/tempcache/*
        ./perf_testing/scripts/fio_bench.sh /mnt/blob_mnt list
      
    - name: "Update Benchmark Results : List"
      uses: benchmark-action/github-action-benchmark@v1
      with:
        output-file-path: list/list_results.json
        tool: 'customSmallerIsBetter'
        alert-threshold: "160%"
        max-items-in-chart: 100
        github-token: ${{ inputs.TOKEN }}
        fail-on-alert: true
        auto-push: true
        comment-on-alert: true
        gh-pages-branch: benchmarks
        benchmark-data-dir-path: ${{ inputs.TYPE }}/time/list

    # ---------------------------------------------------------------------------------------
    # Run App baseed tests
    # This needs to run seperatly as output is different
    - name: "App based Test"
      shell: bash
      run: |
        rm -rf /mnt/blob_mnt/*
        rm -rf /mnt/tempcache/*
        ./perf_testing/scripts/fio_bench.sh /mnt/blob_mnt app

      
    - name: "Update Bandwidth Results : App"
      uses: benchmark-action/github-action-benchmark@v1
      with:
        output-file-path: app/app_bandwidth.json
        tool: 'customBiggerIsBetter'
        alert-threshold: "160%"
        max-items-in-chart: 100
        github-token: ${{ inputs.TOKEN }}
        fail-on-alert: true
        auto-push: true
        comment-on-alert: true
        gh-pages-branch: benchmarks
        benchmark-data-dir-path: ${{ inputs.TYPE }}/bandwidth/app

    - name: "Update Latency Results : App"
      uses: benchmark-action/github-action-benchmark@v1
      with:
        output-file-path: app/app_time.json
        tool: 'customSmallerIsBetter'
        alert-threshold: "160%"
        max-items-in-chart: 100
        github-token: ${{ inputs.TOKEN }}
        fail-on-alert: true
        auto-push: true
        comment-on-alert: true
        gh-pages-branch: benchmarks
        benchmark-data-dir-path: ${{ inputs.TYPE }}/time/app    

    - name: "Update Bandwidth Results : High Speed App"
      uses: benchmark-action/github-action-benchmark@v1
      with:
        output-file-path: app/highapp_bandwidth.json
        tool: 'customBiggerIsBetter'
        alert-threshold: "160%"
        max-items-in-chart: 100
        github-token: ${{ inputs.TOKEN }}
        fail-on-alert: true
        auto-push: true
        comment-on-alert: true
        gh-pages-branch: benchmarks
        benchmark-data-dir-path: ${{ inputs.TYPE }}/bandwidth/highapp   

    - name: "Update Latency Results : High Speed App"
      uses: benchmark-action/github-action-benchmark@v1
      with:
        output-file-path: app/highapp_time.json
        tool: 'customSmallerIsBetter'
        alert-threshold: "160%"
        max-items-in-chart: 100
        github-token: ${{ inputs.TOKEN }}
        fail-on-alert: true
        auto-push: true
        comment-on-alert: true
        gh-pages-branch: benchmarks
        benchmark-data-dir-path: ${{ inputs.TYPE }}/time/highapp  

    # ---------------------------------------------------------------------------------------
    # Run Rename tests
    # This needs to run seperatly as output is different
    - name: "Rename Test"
      shell: bash
      run: |
        rm -rf /mnt/blob_mnt/*
        rm -rf /mnt/tempcache/*
        ./perf_testing/scripts/fio_bench.sh /mnt/blob_mnt rename

    - name: "Update Latency Results : Rename"
      uses: benchmark-action/github-action-benchmark@v1
      with:
        output-file-path: rename/rename_time.json
        tool: 'customSmallerIsBetter'
        alert-threshold: "160%"
        max-items-in-chart: 100
        github-token: ${{ inputs.TOKEN }}
        fail-on-alert: true
        auto-push: true
        comment-on-alert: true
        gh-pages-branch: benchmarks
        benchmark-data-dir-path: ${{ inputs.TYPE }}/time/rename  
    # ---------------------------------------------------------------------------------------          
                        