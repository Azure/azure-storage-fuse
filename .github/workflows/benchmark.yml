name: Benchmark
on:
  schedule:
    - cron: '5 1,3,5,7,9,11,13,15,17,19,21,23 * * *'
  push:
    branches:
      - main
      - vibhansa/perftestrunner

jobs:
  PerfTesting:
    strategy:
      matrix:
        TestType: ["premium", "standard"]
            
    runs-on: [self-hosted, 1ES.Pool=blobfuse2-benchmark]
    timeout-minutes: 360

    permissions:
      id-token: write
      contents: write
      pages: write

    steps:
      # Print the host info
      - name: 'Host info'
        run: hostnamectl
          
      # Install Fuse3
      - name: "Install Fuse3"
        run: |
          sudo apt-get update
          sudo apt-get install fuse3 libfuse3-dev gcc -y

      # Install Tools
      - name: "Install Tools"
        run: |
          sudo apt-get install fio jq python3 -y

        # Checkout main branch
      - name: 'Checkout Blobfuse2'
        uses: actions/checkout@v4.1.1
        # with: 
          # ref: vibhansa/perftestrunner

      # Install GoLang
      - name: "Install Go"
        run: |
          ./go_installer.sh ../
          go version

      # Build Blobfuse2
      - name: "Build Blobfuse2"
        run: |
          ./build.sh

      # Check the paths
      - name: "Check paths"
        run: |
          pwd
          df -h

      # Run binary and validate the version
      - name: "Validate Version"
        run: |
          ./blobfuse2 --version
          pwd
          sudo cp ./blobfuse2 /usr/bin/
          which blobfuse2
          blobfuse2 --version

      - name: "Export environment variable"
        run: |
          echo "export AZURE_STORAGE_ACCOUNT_CONTAINER=benchmark" >> $GITHUB_ENV
          if [ "${{ matrix.TestType }}" == "premium" ]; then
            echo "export AZURE_STORAGE_ACCOUNT=blobfuse2benchmark" >> $GITHUB_ENV
          else
            echo "export AZURE_STORAGE_ACCOUNT=stdblobfuse2benchmark" >> $GITHUB_ENV
          fi

      # Create the config file for testing
      - name: "Create config file"
        run: |
          blobfuse2 gen-test-config --config-file=azure_block_bench.yaml --container-name=${{ secrets.BLOB_STORAGE_CONTAINER }}  --output-file=./config.yaml
          cat ./config.yaml
        env:
          STO_ACC_NAME: $AZURE_STORAGE_ACCOUNT

      # Create the config file for testing
      - name: "Create mount path"
        run: |
          sudo mkdir -p /mnt/blob_mnt
          sudo mkdir -p /mnt/tempcache
          sudo chmod 777 /mnt/blob_mnt
          sudo chmod 777 /mnt/tempcache

      - name: "Check the env variables"
        run: |
          echo $AZURE_STORAGE_ACCOUNT

    # ---------------------------------------------------------------------------------------------------------------------------------------------------
      # Run the basic tests using FIO

      # Run the Write tests
      - name: "Read Test"
        uses: "./.github/template/generate_page"
        with:
          TEST: "read"
          TYPE: ${{ matrix.TestType }}
          TOKEN: ${{ secrets.GITHUB_TOKEN }}

      # Run the Write tests with high number of threads
      - name: "High threads Test"
        uses: "./.github/template/generate_page"
        with:
          TEST: "highlyparallel"
          TYPE: ${{ matrix.TestType }}
          TOKEN: ${{ secrets.GITHUB_TOKEN }}
    
      # Run the Write tests
      - name: "Write Test"
        uses: "./.github/template/generate_page"
        with:
          TEST: "write"
          TYPE: ${{ matrix.TestType }}
          TOKEN: ${{ secrets.GITHUB_TOKEN }}
            
      # Run the Create tests
      - name: "Create File Test"
        uses: "./.github/template/generate_page"
        with:
          TEST: "create"
          TYPE: ${{ matrix.TestType }}
          TOKEN: ${{ secrets.GITHUB_TOKEN }}
      # ---------------------------------------------------------------------------------------


      # Below tests needs to run seperatly as output is different
      # ---------------------------------------------------------------------------------------------------
      # Run the List tests
      # this shall always runs after create tests
      - name: "List File Test"
        shell: bash
        run: |
          rm -rf /mnt/blob_mnt/*
          rm -rf /mnt/tempcache/*
          ./perf_testing/scripts/fio_bench.sh /mnt/blob_mnt list
        
      - name: "Update Benchmark Results : List"
        uses: benchmark-action/github-action-benchmark@v1
        with:
          output-file-path: list/list_results.json
          tool: 'customSmallerIsBetter'
          alert-threshold: "160%"
          max-items-in-chart: 100
          github-token: ${{ secrets.GITHUB_TOKEN }}
          fail-on-alert: true
          auto-push: true
          comment-on-alert: true
          gh-pages-branch: benchmarks
          benchmark-data-dir-path: ${{ matrix.TestType }}/time/list

      # ---------------------------------------------------------------------------------------
      # Run App baseed tests
      # This needs to run seperatly as output is different
      - name: "App based Test"
        shell: bash
        run: |
          rm -rf /mnt/blob_mnt/*
          rm -rf /mnt/tempcache/*
          ./perf_testing/scripts/fio_bench.sh /mnt/blob_mnt app
        
      - name: "Update Bandwidth Results : App"
        uses: benchmark-action/github-action-benchmark@v1
        with:
          output-file-path: app/app_bandwidth.json
          tool: 'customBiggerIsBetter'
          alert-threshold: "160%"
          max-items-in-chart: 100
          github-token: ${{ secrets.GITHUB_TOKEN }}
          fail-on-alert: true
          auto-push: true
          comment-on-alert: true
          gh-pages-branch: benchmarks
          benchmark-data-dir-path: ${{ matrix.TestType }}/bandwidth/app

      - name: "Update Latency Results : App"
        uses: benchmark-action/github-action-benchmark@v1
        with:
          output-file-path: app/app_time.json
          tool: 'customSmallerIsBetter'
          alert-threshold: "160%"
          max-items-in-chart: 100
          github-token: ${{ secrets.GITHUB_TOKEN }}
          fail-on-alert: true
          auto-push: true
          comment-on-alert: true
          gh-pages-branch: benchmarks
          benchmark-data-dir-path: ${{ matrix.TestType }}/time/app    

      - name: "Update Bandwidth Results : High Speed App"
        uses: benchmark-action/github-action-benchmark@v1
        with:
          output-file-path: app/highapp_bandwidth.json
          tool: 'customBiggerIsBetter'
          alert-threshold: "160%"
          max-items-in-chart: 100
          github-token: ${{ secrets.GITHUB_TOKEN }}
          fail-on-alert: true
          auto-push: true
          comment-on-alert: true
          gh-pages-branch: benchmarks
          benchmark-data-dir-path: ${{ matrix.TestType }}/bandwidth/highapp   

      - name: "Update Latency Results : High Speed App"
        uses: benchmark-action/github-action-benchmark@v1
        with:
          output-file-path: app/highapp_time.json
          tool: 'customSmallerIsBetter'
          alert-threshold: "160%"
          max-items-in-chart: 100
          github-token: ${{ secrets.GITHUB_TOKEN }}
          fail-on-alert: true
          auto-push: true
          comment-on-alert: true
          gh-pages-branch: benchmarks
          benchmark-data-dir-path: ${{ matrix.TestType }}/time/highapp  

      # ---------------------------------------------------------------------------------------
      # Run Rename tests
      # This needs to run seperatly as output is different
      - name: "Rename Test"
        shell: bash
        run: |
          rm -rf /mnt/blob_mnt/*
          rm -rf /mnt/tempcache/*
          ./perf_testing/scripts/fio_bench.sh /mnt/blob_mnt rename

      - name: "Update Latency Results : Rename"
        uses: benchmark-action/github-action-benchmark@v1
        with:
          output-file-path: rename/rename_time.json
          tool: 'customSmallerIsBetter'
          alert-threshold: "160%"
          max-items-in-chart: 100
          github-token: ${{ secrets.GITHUB_TOKEN }}
          fail-on-alert: true
          auto-push: true
          comment-on-alert: true
          gh-pages-branch: benchmarks
          benchmark-data-dir-path: ${{ matrix.TestType }}/time/rename  
      # ---------------------------------------------------------------------------------------          
                          